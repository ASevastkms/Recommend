{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import heapq\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'                         \n",
    "data_1 = 'data_learn_match.csv'\n",
    "data_2 = 'data_test_match.csv'\n",
    "data_3 = 'data_target_thread.csv'\n",
    "raw_data = pd.read_csv(os.path.join(data_path, data_1), header=None)\n",
    "raw_data.drop(raw_data.columns[2:3], axis=1, inplace=True)\n",
    "raw_data['values'] = 1\n",
    "raw_data['values_pessimize'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns = ['user_uid', 'thread_uid', 'match_date', 'values', 'values_pessimize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list_1 = raw_data['user_uid'].unique()\n",
    "\n",
    "def scale_user_uid(input_uid):\n",
    "    return np.where(input_list_1 == input_uid)[0][0]\n",
    "\n",
    "raw_data['user_uid_renumber'] = raw_data['user_uid'].apply(scale_user_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list_2 = raw_data['thread_uid'].unique()\n",
    "\n",
    "def scale_thread_uid(input_uid):\n",
    "    return np.where(input_list_2 == input_uid)[0][0]\n",
    "\n",
    "raw_data['thread_uid_renumber'] = raw_data['thread_uid'].apply(scale_thread_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['values_pessimize'] = 15552000/(15552000 + 1570136400 - raw_data['match_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mini = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = data_mini['user_uid'].unique().shape[0]\n",
    "n_items = data_mini['thread_uid'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_2 = pd.read_csv(os.path.join(data_path, data_2), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_2.columns = ['user_uid_test', 'thread_uid_test']\n",
    "data_2 = raw_data_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_3 = pd.read_csv(os.path.join(data_path, data_3), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_3.columns = ['thread_uid_test']\n",
    "data_3 = raw_data_3.copy()\n",
    "list_test_threads = data_3['thread_uid_test'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test_user = data_2['user_uid_test'].unique()\n",
    "list_match_thread = data_mini['thread_uid'].unique()\n",
    "list_match_user = data_mini['user_uid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_drop = list(set(list_test_user).difference(list_match_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = list_test_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test_user_filtered = list(set(list_test_user) - set(list_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_thread = list_match_thread.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_idx = []\n",
    "for thread in tqdm(list_test):\n",
    "    idx = list_thread.index(thread)\n",
    "    list_of_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_item_user = sparse.csr_matrix((data_mini['values'].astype(float), (data_mini['thread_uid_renumber'], data_mini['user_uid_renumber'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_sim = []\n",
    "for idx in tqdm(list_of_idx):\n",
    "    d_sim = []\n",
    "    for i in range(sparse_item_user.shape[0]):\n",
    "        score = distance.jaccard(sparse_item_user[i].toarray(), sparse_item_user[idx:idx+1].toarray())\n",
    "        dice = 2*(1 - score) / (2 - score)\n",
    "        d_sim.append(dice)\n",
    "    dice_sim.append(d_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(dice_sim).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_item_user_pessim = sparse.csr_matrix((data_mini['values_pessimize'].astype(float), (data_mini['thread_uid_renumber'], data_mini['user_uid_renumber'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#чтобы включить пессимизацию, вместо sparse_item_user вставить sparse_item_user_pessim\n",
    "pred = sparse_item_user_pessim.T.dot(A) / np.array([np.abs(A.T).sum(axis=1)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для тестовых юзеров находим их перенумерованный индекс\n",
    "user_test = []                                       \n",
    "for user in list_test_user_filtered:\n",
    "    user_renumber = data_mini['user_uid_renumber'].loc[data_mini['user_uid'] == user].tolist()\n",
    "    user_test.extend(list(set(user_renumber)))\n",
    "user_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = []\n",
    "for i in user_test:\n",
    "    predict = pred[i].tolist()\n",
    "    predict_test.append(predict)\n",
    "predict_test_users = np.array(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#модуль фильтрации по квантилю или по значению сходства\n",
    "rec_len = []\n",
    "for scores in range(len(predict_test_users)):\n",
    "    #quantile = np.quantile(predict_test_users[scores], 0.95)\n",
    "    #для фильтрации по значению: закомментить строку (quantile = ...), а в следующей строке прописать \"x >= значение фильтрации\"\n",
    "    condition = lambda x: x >= 0.004                                  \n",
    "    filtered_scores = list(filter(condition, predict_test_users[scores]))           \n",
    "    len_filtered_scores = len(filtered_scores)\n",
    "    rec_len.append(len_filtered_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threads = []\n",
    "for user in tqdm(range(len(predict_test_users))):\n",
    "    a = heapq.nlargest(rec_len[user], range(len(predict_test_users[user])), predict_test_users[user].take)   \n",
    "    sim = []                                                               \n",
    "    for idx in a:\n",
    "        sim_threads = list_test[idx]\n",
    "        sim.append(sim_threads)\n",
    "    similarity_threads.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2['columns'] = data_2.groupby('user_uid_test')['thread_uid_test'].cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_2.pivot(index='user_uid_test', columns='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['concat_col']=result.apply(lambda row: row.dropna().tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_threads = result[['concat_col']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_threads_f = df_test_threads.drop(list_drop, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_threads_f['sim_threads'] = similarity_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_seen = raw_data.loc[raw_data['user_uid'].isin(list_test_user_filtered)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_seen['columns'] = raw_data_seen.groupby('user_uid')['thread_uid'].cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = raw_data_seen.pivot(index='user_uid', columns='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2['seen_threads']=result_2.apply(lambda row: row.dropna().tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_threads_f['seen_threads'] = result_2['seen_threads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relev = []\n",
    "for x in range(df_test_threads_f.shape[0]):\n",
    "    A = list(set(df_test_threads_f['concat_col'].iloc[x]) & (set(df_test_threads_f['sim_threads'].iloc[x]) - set(df_test_threads_f['seen_threads'].iloc[x])))\n",
    "    relev.append(len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_threads_f['relevant'] = relev\n",
    "df_test_threads_f['len_concat'] = df_test_threads_f['concat_col'].apply(lambda x: len(x))\n",
    "df_test_threads_f['len_predict'] = df_test_threads_f['sim_threads'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_threads_f['precision'] = df_test_threads_f['relevant']/df_test_threads_f['len_predict']\n",
    "df_test_threads_f['recall'] = df_test_threads_f['relevant']/df_test_threads_f['len_concat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = df_test_threads_f['precision'].mean()\n",
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall = df_test_threads_f['recall'].mean()\n",
    "Recall"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
